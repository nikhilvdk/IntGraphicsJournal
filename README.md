# Week 2 Journal
------

### Rain Room
![Random International](images/rainroom.jpg?raw=true "Random International")
![Random International](images/rainroom2.jpg?raw=true "Random International")
The first piece that stood out to me was Random International's Rain Room at MoMA. The rain room is a 1100 sqft exhibition with water falling from the ceiling. Visitors are able to walk though the rain without getting wet due to 3D tracking cameras which are used to sense a person’s presence. It was the first piece that came to my mind when I thought of users interfacing with art through technology. After braving the seemingly endless lines at the MoMA, where you can see the installation from the outside, the observer becomes the participant. Lighting is kept low to invoke dramatic shadows and a sense of obscurity. The sound the rain makes is an almost deafening white noise. This adds to the idea of being cocooned and protected – both physically from the rain, but also audibly and visually. I find it interesting that people are so excited to be immersed in rain, which we usually are so unhappy to encounter. Often times, visitors even try to reach out and touch it if the sensor misses them. Visitors have the freedom to walk through the space, creating the art and escaping to a reality where humans have control over the rain.

[Here's a link to a video about the piece](https://www.youtube.com/watch?v=7cem71cR0S0)


### A Subtlety

![Kara Walker](images/subtlety.jpg?raw=true "Kara Walker")
![Kara Walker](images/subtlety2.jpg?raw=true "Kara Walker")
Another piece that I found really exciting and immersive was Kara Walker’s A Subtlety in Brooklyn’s famous Domino Sugar factory. I was able to go to this exhibit a few years ago and it was an exciting experience. The exhibit is inside an old and decrepit sugar factory that leaks from the ceilings and still has molasses dripping from the walls (I remember having to sign a waiver before entering). Domino allowed the art to exist in the space for a period right before the factory was demolished. The exhibition consisted of smaller sculptures of young children made from molasses which lined the floors, and a giant sphynx-like lady made of sugar that engulfed the room. It was a very immersive experience being in the place that produced the materials for the sculptures. The floors were sticky and the molasses babies were already melting apart, and the smell was cloying, so visitors interacted with the space in tangible ways. It was very meaningful as it referenced slavery and imperialism where sugar was traded for bodies. It was a poignant critique of our fascination with the monumentality of spectacle at a surface level possibly without understanding of backstory.

[Here's a link to the project](http://creativetime.org/projects/karawalker/)




# Week 3 Journal : Hello World Reflection
------
It was exciting to have such an open-ended and exploratory intro to p5.js assignment. I found it quite liberating to experiment with the whole processing library at my fingertips. At first, I was confused about how the draw method worked, and why I was encountering image persistence when drawing a moving/animated shape. It was also confusing figuring out how to have multiple shapes on the same canvas moving at different intervals. Through documentation and google searching, I encountered a familiar concept of popping and pushing applied in a new, creative perspective that helped solve my "multi-shape" dilemma. As I began implementing moving shapes, I began to formulate an idea of a general theme/concept behind the piece. Throwing back to my highschool interests in astrophysics, I decided to make my sketch an abstract solar system. Following this, I started getting ideas for different distinctive planets, gathering inspiration for different pulsating movements and uses for "framecount" from various p5.js examples online. Along the way, I had further difficulties trying to draw a moving ellipse at a rotated offset. 

Moving forward, I should have probably asked for more direct assistance because I ended up spending too long trolling web forums for solutions. Sometimes I jump into creating pretty quickly, so it may have been beneficial to read through a more comprehensive intro/basics guide before starting. Later in the process, I decided to move some actions/shapes into separate functions in case I would need to call them in multiple circumstances. After further research, I was also able to add interactivity by clicking the sun to create a black hole and by pressing the keyboard to "save the world" and stop the sketch before it was consumed by darkness. Unfortunately I also didnt realize a console logger could be used to debug until later in the process, which did come in handy when implementing interactivity features. As it was such a dynamic process, along the way there were a few components that ended up getting commented out including the "cosmic background" randomly generated moving shapes across the screen. Though this added to the effect, I felt that it was slowing the animation down due to its processing intensity. 

Though I already had some basic familiarity with HTML/CSS and Git, and general coding principles, I have definitely already learned many new things: like Visual Studio code and its super useful interface, packages and testing environment (pretty lifechanging). I believe that class has been moving at a good pace that takes everyone's backgrounds into mind, and I bet it will be picking up soon as we dive into new topics. Overall I am quite happy with my piece, and I feel that even though the semester is young, I have already learned quite a lot about interactive graphics.


# Week 5 Journal : Chance Operations
------
Though it may be a bit more guided than pure chance, when you let a neuralnet show you its dreams you might get lucky with some crazy pieces of art. Google’s DeepDream technology primarily elicits creepy feelings, but it’s pieces are also so fascinating, otherworldly and intriguing that you cant help but take a closer look. Google used cutting edge technology to prove the seemingly creative power of artificial brains. After training neural networks using advanced computer vision techniques, it is now common knowledge that provided with a large enough training set, computers can be taught to identify specific objects in images. However, instead of identifying objects, if a user asks the algorithm to produce images of what it understands the objects are, you get an abstract and trippy view into the mind of the machine. Further building off an understanding that the algorithms analyze very specific features of the image - embedded details of edge relationships and color gradients - that us humans have a harder time explaining (though our own brains may be doing similar things subconsciously), we can ask the machine to emphasize those features to see what is most important to it in the image. Enhancing some of these particular neurons result in some very interesting graphics that are often visually stunning. Further interesting pieces arise when you allow the AI to “day dream” at the clouds like we do. Presenting an algorithm with cloud pictures after it was trained on pictures of animals has some very interesting results, as it overanalyzes the clouds and starts to create mutant perceptions of animals in the sky, or similarly seeing pagodas instead of trees. Some visually stunning pieces come from when you let the algorithm iteratively zoom and build impressions off its own creations. Though it may seem worrisome that computers have their own (psuedo) agency and interpretations, and ability to create unique art, I am excited by the possibilities it brings for human artists to be inspired and to use the machines analytical power to realize their own dreams.

I particularly loved the use of DeepDream in Foster the People’s new [music video](https://www.youtube.com/watch?v=dJ1VorN9Cl0). I can definitely guess what a large portion of the image training set on this net may have been. 

![Google](images/clouds.png?raw=true "Google")
![Google](images/animals.png?raw=true "Google")
![Google](images/dreamcreations.png?raw=true "Google")

When looking at more traditional pieces, I found it interesting to see how chance was used by modern artists like Ellsworth Kelly, who used chance in the '50s in a minimalist way to understand relationships between color, and to turn ideas of "organized", "right" and "wrong" on their heads. Interestingly, Kelly was actually inspired by nature - which is very often chaotic and seemingly random, or too complex to model or explain (though on occasion it can be the opposite - see golden ratios!). After seeing light fragmented on the surface of the seine river in south France, he was inspired to recreate the chaotic, enchanting lights in a non-direct way - writing down numbers corresponding to blocks on a canvas, and only painting the ones he picked out on the canvas. This resulted in a piece of “pixel art” before there were any serious computer graphics. Though you may not be able to recognize it immediately, it definitely evokes feelings of movement and chance. Later, experimenting with many different colors, Kelly expressed his thoughts that chance took away the pressure or fear of approaching abstract art. The free, playfulness of chance felt slightly less crazy than “random” but was still out of the hands of the artist, so in a way, the piece created itself. I think amazing new levels of creativity and visually pleasing pieces can result from “chance” art like Kelly’s pieces, but even the crazy and conventionally ugly pieces can get viewers thinking and imagining in a way that “normal” thought out and “clean” art my not.

![Ellsworth Kelly](images/seine.jpg?raw=true "Ellsworth Kelly")
![Ellsworth Kelly](images/spectrumchance.png?raw=true "Ellsworth Kelly")


# Week 6 Journal : Algorithms
------
So far, in this class, I have begun to appreciate the complexity and balance needed in “successful” algorithmic design. The ability to harness intense computing power in order to create intricate art pieces opens many new doors to either more accurately reproduce patterns, scenes and phenomena that we see in nature or bring to light abstract concepts that previously could only live in the imagination. While you might understand your vision, and give the computer instructions on from a “human” level of abstraction, the computer makes its own interpretation (if you don’t communicate perfectly and miscode something for example) and create something different. Its not possible for humans to understand every layer of a complex neural net or to manually construct a fractal tree before a result has “magically” been spat out by the algorithm. Running and tweaking is a crucial component to the process, and I believe that it adds to the inspiration and creativity of the artist. I find it exhilarating to give up complete control of the piece. Though I still want the abide by my specific vision and guidelines, along the way while debugging, if I encounter an “error” piece that happens to connect with my intentions, I will alter my perspectives, incorporating it or drawing inspiration from it.

In this way, though I like the randomness of using chance operations in art, I find that there there can be such a thing as a “wrong” random. When creating my piece for example, I didn’t like it when two of the fractal trees happened to iterate on very similar number of branches, and ended up looking similar when my overall vision was to have them all look different. Similarly, with random particle motion, the artist often intends for an aesthetic randomness which is spread out and more “uniform”, a beauty that is added to by the fact that it is advertised as being created “randomly”.  Or the twitter searching AI that created headlines pulling from many sources may fail and pull up completely random words that would take a imaginative stretch to mesh into a meaningful/provocative takeaway for a viewing. However, it is inherent to real chance that this is often not realizable. On a practical note, randomness and chance is difficult for the computer as much as it is for us. I had issues at one point when too many random calculations were being performed at every draw() refresh.

In order to keep a sense of structure to your piece, a framework must initially be set manually by the artist. In both code and in physical artwork to keep the art in check. It may be a training set of animals for Google’s DeepDream to imagine creatures in the clouds or a range of acceptable number of leaves or tree branch iterations in my “Fall” piece. But though machines are very powerful, they are dumb to implied intentions so some creative decisions must be made before handing the “paintbrush” off. Even in Ellsworth Kelly’s pieces, a refined grid system was used along with numbers that he had set up to be “randomly” chosen from a hat. In this way, the art cannot ever be completely attributed to the algorithm, as some parameters for control over color, size and creative direction must be set for the algorithm. It is then up to the algorithm to behave well and follow intended guides, or to mess up and return to the artist to see if they want to refine the parameters to align with this new vision the algorithm has presented.
