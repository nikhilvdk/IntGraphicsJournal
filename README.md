# Week 2 Journal
------

### Rain Room
![Random International](images/rainroom.jpg?raw=true "Random International")
![Random International](images/rainroom2.jpg?raw=true "Random International")
The first piece that stood out to me was Random International's Rain Room at MoMA. The rain room is a 1100 sqft exhibition with water falling from the ceiling. Visitors are able to walk though the rain without getting wet due to 3D tracking cameras which are used to sense a person’s presence. It was the first piece that came to my mind when I thought of users interfacing with art through technology. After braving the seemingly endless lines at the MoMA, where you can see the installation from the outside, the observer becomes the participant. Lighting is kept low to invoke dramatic shadows and a sense of obscurity. The sound the rain makes is an almost deafening white noise. This adds to the idea of being cocooned and protected – both physically from the rain, but also audibly and visually. I find it interesting that people are so excited to be immersed in rain, which we usually are so unhappy to encounter. Often times, visitors even try to reach out and touch it if the sensor misses them. Visitors have the freedom to walk through the space, creating the art and escaping to a reality where humans have control over the rain.

[Here's a link to a video about the piece](https://www.youtube.com/watch?v=7cem71cR0S0)


### A Subtlety

![Kara Walker](images/subtlety.jpg?raw=true "Kara Walker")
![Kara Walker](images/subtlety2.jpg?raw=true "Kara Walker")
Another piece that I found really exciting and immersive was Kara Walker’s A Subtlety in Brooklyn’s famous Domino Sugar factory. I was able to go to this exhibit a few years ago and it was an exciting experience. The exhibit is inside an old and decrepit sugar factory that leaks from the ceilings and still has molasses dripping from the walls (I remember having to sign a waiver before entering). Domino allowed the art to exist in the space for a period right before the factory was demolished. The exhibition consisted of smaller sculptures of young children made from molasses which lined the floors, and a giant sphynx-like lady made of sugar that engulfed the room. It was a very immersive experience being in the place that produced the materials for the sculptures. The floors were sticky and the molasses babies were already melting apart, and the smell was cloying, so visitors interacted with the space in tangible ways. It was very meaningful as it referenced slavery and imperialism where sugar was traded for bodies. It was a poignant critique of our fascination with the monumentality of spectacle at a surface level possibly without understanding of backstory.

[Here's a link to the project](http://creativetime.org/projects/karawalker/)




# Week 3 Journal : Hello World Reflection
------
It was exciting to have such an open-ended and exploratory intro to p5.js assignment. I found it quite liberating to experiment with the whole processing library at my fingertips. At first, I was confused about how the draw method worked, and why I was encountering image persistence when drawing a moving/animated shape. It was also confusing figuring out how to have multiple shapes on the same canvas moving at different intervals. Through documentation and google searching, I encountered a familiar concept of popping and pushing applied in a new, creative perspective that helped solve my "multi-shape" dilemma. As I began implementing moving shapes, I began to formulate an idea of a general theme/concept behind the piece. Throwing back to my highschool interests in astrophysics, I decided to make my sketch an abstract solar system. Following this, I started getting ideas for different distinctive planets, gathering inspiration for different pulsating movements and uses for "framecount" from various p5.js examples online. Along the way, I had further difficulties trying to draw a moving ellipse at a rotated offset. 

Moving forward, I should have probably asked for more direct assistance because I ended up spending too long trolling web forums for solutions. Sometimes I jump into creating pretty quickly, so it may have been beneficial to read through a more comprehensive intro/basics guide before starting. Later in the process, I decided to move some actions/shapes into separate functions in case I would need to call them in multiple circumstances. After further research, I was also able to add interactivity by clicking the sun to create a black hole and by pressing the keyboard to "save the world" and stop the sketch before it was consumed by darkness. Unfortunately I also didnt realize a console logger could be used to debug until later in the process, which did come in handy when implementing interactivity features. As it was such a dynamic process, along the way there were a few components that ended up getting commented out including the "cosmic background" randomly generated moving shapes across the screen. Though this added to the effect, I felt that it was slowing the animation down due to its processing intensity. 

Though I already had some basic familiarity with HTML/CSS and Git, and general coding principles, I have definitely already learned many new things: like Visual Studio code and its super useful interface, packages and testing environment (pretty lifechanging). I believe that class has been moving at a good pace that takes everyone's backgrounds into mind, and I bet it will be picking up soon as we dive into new topics. Overall I am quite happy with my piece, and I feel that even though the semester is young, I have already learned quite a lot about interactive graphics.


# Week 5 Journal : Chance Operations
------
Though it may be a bit more guided than pure chance, when you let a neuralnet show you its dreams you might get lucky with some crazy pieces of art. Google’s DeepDream technology primarily elicits creepy feelings, but it’s pieces are also so fascinating, otherworldly and intriguing that you cant help but take a closer look. Google used cutting edge technology to prove the seemingly creative power of artificial brains. After training neural networks using advanced computer vision techniques, it is now common knowledge that provided with a large enough training set, computers can be taught to identify specific objects in images. However, instead of identifying objects, if a user asks the algorithm to produce images of what it understands the objects are, you get an abstract and trippy view into the mind of the machine. Further building off an understanding that the algorithms analyze very specific features of the image - embedded details of edge relationships and color gradients - that us humans have a harder time explaining (though our own brains may be doing similar things subconsciously), we can ask the machine to emphasize those features to see what is most important to it in the image. Enhancing some of these particular neurons result in some very interesting graphics that are often visually stunning. Further interesting pieces arise when you allow the AI to “day dream” at the clouds like we do. Presenting an algorithm with cloud pictures after it was trained on pictures of animals has some very interesting results, as it overanalyzes the clouds and starts to create mutant perceptions of animals in the sky, or similarly seeing pagodas instead of trees. Some visually stunning pieces come from when you let the algorithm iteratively zoom and build impressions off its own creations. Though it may seem worrisome that computers have their own (psuedo) agency and interpretations, and ability to create unique art, I am excited by the possibilities it brings for human artists to be inspired and to use the machines analytical power to realize their own dreams.

I particularly loved the use of DeepDream in Foster the People’s new [music video](https://www.youtube.com/watch?v=dJ1VorN9Cl0). I can definitely guess what a large portion of the image training set on this net may have been. 

![Google](images/clouds.png?raw=true "Google")
![Google](images/animals.png?raw=true "Google")
![Google](images/dreamcreations.png?raw=true "Google")

When looking at more traditional pieces, I found it interesting to see how chance was used by modern artists like Ellsworth Kelly, who used chance in the '50s in a minimalist way to understand relationships between color, and to turn ideas of "organized", "right" and "wrong" on their heads. Interestingly, Kelly was actually inspired by nature - which is very often chaotic and seemingly random, or too complex to model or explain (though on occasion it can be the opposite - see golden ratios!). After seeing light fragmented on the surface of the seine river in south France, he was inspired to recreate the chaotic, enchanting lights in a non-direct way - writing down numbers corresponding to blocks on a canvas, and only painting the ones he picked out on the canvas. This resulted in a piece of “pixel art” before there were any serious computer graphics. Though you may not be able to recognize it immediately, it definitely evokes feelings of movement and chance. Later, experimenting with many different colors, Kelly expressed his thoughts that chance took away the pressure or fear of approaching abstract art. The free, playfulness of chance felt slightly less crazy than “random” but was still out of the hands of the artist, so in a way, the piece created itself. I think amazing new levels of creativity and visually pleasing pieces can result from “chance” art like Kelly’s pieces, but even the crazy and conventionally ugly pieces can get viewers thinking and imagining in a way that “normal” thought out and “clean” art my not.

![Ellsworth Kelly](images/seine.jpg?raw=true "Ellsworth Kelly")
![Ellsworth Kelly](images/spectrumchance.png?raw=true "Ellsworth Kelly")


# Week 6 Journal : Algorithms
------
So far, in this class, I have begun to appreciate the complexity and balance needed in “successful” algorithmic design. The ability to harness intense computing power in order to create intricate art pieces opens many new doors to either more accurately reproduce patterns, scenes and phenomena that we see in nature or bring to light abstract concepts that previously could only live in the imagination. While you might understand your vision, and give the computer instructions on from a “human” level of abstraction, the computer makes its own interpretation (if you don’t communicate perfectly and miscode something for example) and create something different. Its not possible for humans to understand every layer of a complex neural net or to manually construct a fractal tree before a result has “magically” been spat out by the algorithm. Running and tweaking is a crucial component to the process, and I believe that it adds to the inspiration and creativity of the artist. I find it exhilarating to give up complete control of the piece. Though I still want the abide by my specific vision and guidelines, along the way while debugging, if I encounter an “error” piece that happens to connect with my intentions, I will alter my perspectives, incorporating it or drawing inspiration from it.

In this way, though I like the randomness of using chance operations in art, I find that there there can be such a thing as a “wrong” random. When creating my piece for example, I didn’t like it when two of the fractal trees happened to iterate on very similar number of branches, and ended up looking similar when my overall vision was to have them all look different. Similarly, with random particle motion, the artist often intends for an aesthetic randomness which is spread out and more “uniform”, a beauty that is added to by the fact that it is advertised as being created “randomly”.  Or the twitter searching AI that created headlines pulling from many sources may fail and pull up completely random words that would take a imaginative stretch to mesh into a meaningful/provocative takeaway for a viewing. However, it is inherent to real chance that this is often not realizable. On a practical note, randomness and chance is difficult for the computer as much as it is for us. I had issues at one point when too many random calculations were being performed at every draw() refresh.

In order to keep a sense of structure to your piece, a framework must initially be set manually by the artist. In both code and in physical artwork to keep the art in check. It may be a training set of animals for Google’s DeepDream to imagine creatures in the clouds or a range of acceptable number of leaves or tree branch iterations in my “Fall” piece. But though machines are very powerful, they are dumb to implied intentions so some creative decisions must be made before handing the “paintbrush” off. Even in Ellsworth Kelly’s pieces, a refined grid system was used along with numbers that he had set up to be “randomly” chosen from a hat. In this way, the art cannot ever be completely attributed to the algorithm, as some parameters for control over color, size and creative direction must be set for the algorithm. It is then up to the algorithm to behave well and follow intended guides, or to mess up and return to the artist to see if they want to refine the parameters to align with this new vision the algorithm has presented.


# Week 8 Journal : Data Pieces
------

![Will Geary](images/nyctransit.jpg?raw=true "NYC Transit")
[Video Link](https://vimeo.com/231002191)
### Transitflow
Recently, I spoke with Duke grad, [Will Geary](http://willgeary.github.io/) about his work in data visualization specifically in the area of geospatial data. I was excited to hear about a project of his that was of particular interest and relevance to me as a resident of NYC. His project involved using Processing, Python and a mapping software to create visualizations of public transit systems in urban environments in order to understand transit frequency and practicality of the infrastructure. He accomplished this by combining information from timetables and static maps. After pulling data from the Transitland API on stops, routes and schedule-pairs, he created a processing animation sketch by matching stop points and synchronizing the colored points with arrival times. It is interesting to be able to visualize the flow and ebb of the transit-scape especially when it is set to classical music. Not only is it a visually hypnotic set of pieces, but it is also a useful tool to better visualize urban sprawl, get a sense of how service changes during rush hours, pinpoint lines or regions which aren’t being serviced properly, or even just to understand how organized and convenient public transit can be. It is exciting to see open-source tools like this that are easily extended and applied to different metropolitan areas and transport modes.
[Project Link](https://mapzen.com/blog/animating-transitland/)


![Quantified Selfie](images/quantifiedselfie.jpg?raw=true "Quantified Selfie")
### Quantified Selfie: Rocky Beginnings
The second piece that I found is more focused on telling a story. Using music listening information from Spotify, the artist relives the first year after she moved to New York through the songs she listened to the most, and the emotions they made her feel. As you scroll past the introduction, all of the songs scatter in the background, and you can hover over them to see the title and artist and corresponding emotion. As you keep scrolling, the story continues, and describes how she initially felt lonely in the big city and how she has since come to love her new home. The song dots rearrange on a timeline to see what time of day and time of year she listened to each song. You can see a trend in listening to more music that made her feel happy by the end of the year. Next, music is framed through her emotions after a breakup (this includes Since U Been Gone by Kelly Clarkson, Shake it Off by Taylor Swift, and Best Thing I Never Had by Beyonce). As the journey continues, songs that helped her get through different emotions after her breakup automatically play as their corresponding dots dance in the background. The total list of songs is presented at the end of her journey.

I found this to be an interesting and different type of interactive and story driven data visualization that was of particular interest to me as I am curious about music listening habits and the emotions associated with them. The overall site (Quantified Selfie) makes a great point that we are the biggest creators of data points throughout our daily lives and interactions. It is often haunting, sad or nostalgic to look back in a summarized way with “digitally assisted remembering”. The site (that also includes visualizations of email trends between a woman and her ex) poses the question if these memories were meant to be left behind or if being able to analyze and reflect with data is useful to trigger memories and reflect and understand your own life. I personally really do enjoy being able to leave some digital footprints that I can look back on to better understand how the experiences I have lived has affected my (technological) behavior.
[Link to Project](http://quantifiedselfie.us/nyc365/)



# Week 11 Journal : Connecting Things Pieces

### [Reflektor Music Video - Arcade Fire](https://www.justareflektor.com)

Arcade Fire has many really cool and interesting music "videos" that require user interaction or connection. This music video experience (which was created by the band in conjunction with Google) was particularly exciting for me as it was an actually meaningful use of technology that connected to the theme and subject of the song.

In the video, your phone acts as the Reflektor, that you must point at the screen and move around to shine a light, exposing and blurring/blending the video and focusing on subjects moving through Haiti while partially obscuring your own view. Your interaction drives how the subjects of the video are presented, changing colors or finding them in the darkness. Towards the end, you even control beams of light that connect to the subject - making it look almost like you are controlling a puppet on strings.

The video and lyrics begin to comment on an uneasy relationship we have with technology. Lyrics include “We’re so connected, but are we even friends?” and “we fell in love at 19, and I was staring at a screen”. In the end, dark characters surround the dancer protagonist using the technology light beams in an aggressive, controlling way. The protagonist dancer then shatters the mirror tablet and you see yourself symbolically throught the cracks in the reflektor. The user then has to break free of the technology in your tethered Reflektor and your phone becomes an obsolete technology shell. If you try to use the Reflektor again, you are consistenly reminded to "break free". The protagonist is then liberated to continue dancing through a parade of people. Overall, I found this to be a really exciting and powerful use of connected devices to bring the music video into the modern, interactive age. 



### [Aristotle's Office by Hollington & Kyprianou](http://www.electronicsunset.org/node/310)

I came across a very interesting, piece that seemed to provide commentary on the idea of physical computing and "connected things" itself. In this piece, we try to understand how different household objects (answer machine, bin, fan, filing cabinets, lamp, plant, telephone, watercooler) would interact with one another minimizing the human intermediary. What would their relationship be like? How do they interact?

Using minimally programmed interaction rules, these different objects are hooked up to a central panel. The different objects send electrical signals through to the board and different events are triggered based of the signals sent and recieved by each object. Though this might just be electrical interactions, it is interesting to see it in the light of "how does the cabinet respond when the fan starts spinning really fast nearby", or "how will the plant move with the water cooler".

Its interesting to see the idea of humans being able to exersize control over objects and forcing them to communicate to convey our messages flipped on its head, and to instead see their perspective and how they interact. I also like to see physical computing/IOT explored in a not completely utilitarian way, examining the nature of how non-sentient things can be given a voice to interact (even these non electronic items like plants and trash bins).





# Week 15 Journal : Reflection

I am very happy with my experiences in ISS 294: Interactive Graphics Critical Code. Though I had some previous experience in algorithms and computer science theory, this class was a really great opportunity for me to gain further practical CS skills through a creative and artistic lens. Though I have always enjoyed modern and contemporary art, I have never considered myself to be the most artistically talented when it comes to painting or drawing. I was excited by the opportunities and windows that p5.js opened for me to engage and create media in an "unconventional" way through frameworks I was familiar with. Sketching with code allowed me to create dynamic pieces that could be generated randomly or algorithmically and that could be interacted with by the user but could never have been made on paper. I was not only excited to learn how to use js to create sketches from my imagination but also to learn workflow tools like VS Code's simpleserver, how to run node.js on the backend and how to showcase sketches on heroku/GitHub. I also appreciated the time we put into studying new media artists and having critiques of each others' pieces - providing inspiration and creative perspective for how art has evolved and how far reaching and engaging it can be.



I was particularly excited by the class' topic on data visualization. As the amount of data available in the world skyrockets, there is an increasing need to organize and visualize it in meaningful ways. I was excited to dive deeper into this area and explore unconventional methods for telling a story and relaying raw information. I was further suprised to realize how many js libraries there were out there and their potential to be used for an endless range of scenarios. Engaging with computer vision and face tracking using FaceOSC was also particularly exciting since I expected that the "barrier to use" would be much higher as it is such a modern/current technology. I was excited to realize that integrating with the physical world and IOT devices like photons or raspberry pi's is more feasible than I thought. 



In terms of challenges, I occasionally found it difficult to ideate and come up with creative, artistic concepts that could be realized knowing the skills that I have. On top of that, challenge also lay in the aesthetic design of the art pieces. I often found myself gaining inspiration by studying the tools/capabilities offered by p5.js as opposed to coming up with an idea in isolation only to realize that its technical realization would not be feasible. But now that I am more aware and comfortable with my/p5's capabilities, I have a wider inspiration landscape to explore. On top of that, it was definitely a challenge to go beyond the basic color and shape schemes of sketches and try to keep up with advanced levels of graphic design that we have been spoiled with so much online these days. I was glad to be pushed outside of my comfort zone in this creative way. 



Overall, I am very happy that I was able to take this course. It was exciting to really dive into new media and learn about the directions art is expanding into. It was both fun, and a good challenge that expanded my horizons both artistically and technically. 



Sharing my portfolio:



<img src="/images/SharePortfolio.jpg" width="700">